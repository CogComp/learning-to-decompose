from transformers import T5ForConditionalGeneration, T5Tokenizer
import torch


possible_dict = {0: [386, 3, 3074, 3718, 2696, 5910, 792, 2076, 414, 2463, 1442, 2467, 15011, 3875, 2346, 2475, 3499, 5547, 812, 945, 3506, 4406, 568, 9400, 1338, 4537, 11322, 3902, 8640, 833, 1348, 456, 6605, 335, 4316, 220, 4579, 1128, 5353, 491, 3702, 381], 2463: [3, 24, 209, 204, 19, 1], 3: [2544, 9, 7066, 17924, 17396, 14574, 7015, 8738, 89], 2544: [3902, 2346, 9400, 2475, 945, 414, 456, 2467, 833, 1128, 5910, 3718, 812, 5353, 3499, 4537, 3875, 4316], 3902: [19, 13, 1], 19: [220, 3, 756, 534, 44, 2475, 666, 2186, 646, 269, 2755, 945, 59, 3902, 9400, 2346, 359, 386, 2467, 335, 1442, 1128, 414, 491, 833, 456, 5353, 15011, 2076, 3499, 8640, 4579, 3718, 5910, 4406, 21, 3875, 4537, 4316, 568, 812], 220: [5075, 2028, 1], 5075: [42, 1, 11, 19], 42: [431, 2463, 3, 220, 80, 2041, 2069, 2766, 5580, 9681, 2735, 21659, 2634, 285], 431: [5075], 2346: [19, 1, 13], 9: [22734, 123, 1045, 162, 1], 22734: [11, 1, 42, 19], 11: [3, 24], 24: [19, 2463, 72, 8, 59, 192, 65, 44, 705, 1250, 2311, 6605, 2696], 756: [2463, 1, 11, 44, 19, 192, 72, 705, 8], 209: [11, 1, 19, 59, 42], 534: [19, 1, 11], 44: [167, 709], 167: [9400, 3902, 381, 2475, 192, 220, 414, 3, 386, 335, 8640, 3718, 812, 15011, 4537, 3875, 4406, 5910, 456, 833], 9400: [13, 19, 1], 13: [2463, 1, 11, 945, 2346, 8, 19, 705, 192, 44, 5547, 1338, 72, 2467, 1128, 3, 3499, 5353, 2696, 6605, 3506, 4316, 11322, 568], 2475: [13, 19, 1], 666: [2463, 11, 1, 705, 8, 44, 19, 72, 192], 2186: [145], 145: [9400, 3902, 192, 2475, 220, 335, 386, 3, 414, 833, 8640, 812, 3718, 15011, 5910, 4537, 3875, 4406, 456], 646: [13], 269: [13], 2755: [145], 59: [19, 220, 3, 491, 335, 1442, 386, 3499, 5353, 4579, 8640, 15011, 4406, 2311, 1128, 2467, 2076], 709: [9400, 2475, 3902, 192, 381, 220, 3, 414, 335, 456, 833, 3718, 15011, 8640, 5910, 812, 3875, 4406, 4537, 386], 204: [1, 19, 11, 42], 72: [145], 192: [2463, 2346, 945, 1338, 1128, 2467, 3499, 5353, 3506, 11322, 4316, 2696], 8: [167, 2015, 709, 3], 381: [13], 945: [19, 13, 1], 705: [145], 65: [8, 705, 44, 72, 192, 3], 123: [346], 346: [1], 2015: [2475, 3902, 9400, 414, 456, 3718, 5910, 812, 3875, 4537, 833], 1348: [9400, 2475, 3718, 812, 3875, 4537, 3902], 792: [2475, 812, 3718, 4537, 3875, 3902, 9400], 1338: [3, 24, 1], 414: [97], 97: [19, 13, 1], 335: [265], 265: [42, 1, 11, 15], 2028: [1], 359: [11, 1], 386: [716], 716: [1, 11, 42], 456: [97], 5547: [1518], 1518: [413], 413: [1, 42, 11], 2467: [15], 15: [15, 19, 13, 1, 2815, 9, 115], 491: [867], 867: [1, 11, 42], 833: [19, 1, 13], 7066: [204, 220], 568: [24, 1], 1128: [19, 24, 13, 1], 1442: [2235], 2235: [6913], 6913: [1, 11, 42], 80: [1781], 1781: [1], 2041: [1132], 1132: [1], 17924: [833, 3718, 5910, 812, 4537, 3875, 456, 414, 2475, 9400, 3902], 2069: [828], 828: [1], 17396: [1], 5353: [24, 13, 19, 1], 3499: [1745, 686], 1745: [1, 3, 24], 5910: [833], 1250: [3887, 10003], 3887: [1, 11], 3718: [3170], 3170: [19, 13, 1], 14574: [1394], 1394: [265], 2815: [1, 42, 11], 15011: [3740], 3740: [42, 1, 11], 2766: [3740], 812: [19, 13, 1], 8640: [2812], 2812: [1922], 1922: [42, 1, 11], 5580: [2812], 10003: [11, 1], 2076: [3540], 3540: [4653], 4653: [1, 11, 42], 686: [24, 13, 1, 19], 1045: [562, 3827], 562: [11, 1], 3827: [1, 11], 7015: [2253], 2253: [3], 162: [1], 4579: [11, 1, 42], 8738: [7], 7: [15], 9681: [1], 89: [15], 115: [220], 2696: [3, 24, 1, 19, 2311], 4406: [11, 1, 42, 19, 2311], 21: [3074, 72, 8, 1, 44, 705, 3506, 192, 11], 3074: [1, 19, 11, 42, 2311], 3875: [97], 4537: [97], 6605: [25512], 25512: [1, 2311, 19, 59, 42], 2311: [3702, 192, 11322, 1, 8, 44, 705, 11, 72], 3702: [1, 11, 19, 42, 2311], 3506: [1, 24], 11322: [1, 24], 2735: [1], 4316: [1, 19, 13], 21659: [1], 2634: [1], 285: [1033], 1033: [2311, 19, 1]}
alls = [1, 3074, 3, 17924, 7, 8, 9, 1033, 11, 13, 15, 19, 2069, 534, 1045, 24, 21, 2076, 8738, 42, 44, 4653, 562, 568, 11322, 59, 65, 72, 2634, 80, 89, 97, 3170, 1128, 1132, 115, 3702, 123, 646, 3718, 2696, 2186, 145, 666, 21659, 3740, 162, 15011, 167, 686, 2735, 9400, 2235, 192, 705, 2755, 709, 204, 716, 22734, 2766, 2253, 209, 1745, 220, 4316, 1250, 5353, 14574, 3827, 756, 1781, 2812, 2815, 6913, 2311, 265, 269, 10003, 5910, 792, 285, 3875, 2346, 812, 3887, 4406, 1338, 828, 3902, 833, 1348, 335, 346, 867, 359, 7015, 1394, 381, 386, 1922, 7066, 413, 414, 2463, 1442, 2467, 25512, 2475, 5547, 3499, 431, 945, 3506, 4537, 8640, 456, 5580, 6605, 9681, 5075, 3540, 2015, 4579, 491, 2028, 1518, 2544, 17396, 2041]


# This is used only for Overnight experiments, because the setting assumes that the vocabulary orders are known.
def prefix_allowed_tokens_fn(batch_id, input_ids):
    if input_ids.nelement() == 0:
        return alls
    iid = int(input_ids[-1])
    if iid in possible_dict:
        return possible_dict[iid]
    return alls


# @train_model_path: trained model for a specific dataset
# @data_file: source evaluation data file, e.g., ../data/torque/test.txt
# @output_file: an output file path, where each line will be [INPUT]\t[GOLD_OUTPUT]\t[GEN1]...\t[GEN10]
def gen_output(train_model_path, data_file, output_file):
    device = "cuda:0" if torch.cuda.is_available() else "cpu"
    model = T5ForConditionalGeneration.from_pretrained(train_model_path).to(device)
    model.eval()
    tokenizer = T5Tokenizer.from_pretrained("t5-large")
    lines = [x.strip() for x in open(data_file).readlines()]
    f_out = open(output_file, "w")
    for line in lines:
        inputs = tokenizer(line.split("\t")[0], return_tensors="pt").to(device)
        generated_output = model.generate(**inputs, num_beams=10, num_return_sequences=10, forced_eos_token_id=1, max_length=64)
        outs = [line]
        for i, beam_output in enumerate(generated_output):
            outs.append(tokenizer.decode(beam_output, skip_special_tokens=True))
        f_out.write("\t".join(outs) + "\n")
        f_out.flush()


# @data_file: source evaluation data file
# @generation_file: outputs from gen_output()
def evaluate_top(data_file, generation_file):
    gold_lines = [x.strip() for x in open(data_file).readlines()]
    pred_lines = [x.strip() for x in open(generation_file).readlines()]
    total = 0
    correct = 0
    correct_5 = 0
    correct_10 = 0
    for i in range(0, len(gold_lines)):
        total += 1
        gold_sequence = gold_lines[i].split("\t")[1][:-5]
        pred_sequence = pred_lines[i].split("\t")[2:]
        if gold_sequence in pred_sequence[:1]:
            correct += 1
        if gold_sequence in pred_sequence[:5]:
            correct_5 += 1
        if gold_sequence in pred_sequence:
            correct_10 += 1
    print(float(correct) / total)
    print(float(correct_5) / total)
    print(float(correct_10) / total)


# Example usage
# evaluate_top("../data/overnight/test.txt", "reported_outputs/top_gen_overnight_seed10.txt")
